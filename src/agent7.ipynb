{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T18:39:19.833436Z",
     "start_time": "2025-05-09T18:39:19.830910Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import ollama\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T18:39:19.885010Z",
     "start_time": "2025-05-09T18:39:19.882943Z"
    }
   },
   "outputs": [],
   "source": [
    "# Agent 7: Ethics & Risk Checker\n",
    "# Reads project ideas and flags bias, misuse risk, privacy, and explainability issues.\n",
    "# Provides a risk level (low, medium, high) for each and mitigation suggestions.\n",
    "INPUT_FILE = 'output/agent2_ideas.json'\n",
    "OUTPUT_FILE = 'output/agent7_risks.json'\n",
    "\n",
    "# LLM_MODEL = 'llama3.2:3b'\n",
    "AGENT_7 = 'qwen3:32b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T18:39:19.934866Z",
     "start_time": "2025-05-09T18:39:19.932650Z"
    }
   },
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are Agent 7: an Ethics & Risk Checker for climate-change AI projects.\n",
    "\n",
    "Project idea:\n",
    "Title: {title}\n",
    "Description: {description}\n",
    "ID: {idea_id}\n",
    "\n",
    "Considering the following potential risks in AI systems:\n",
    "- BIAS: Does the system risk reinforcing existing inequities or disadvantaging certain groups?\n",
    "- MISUSE: Could bad actors exploit this system for harmful purposes?\n",
    "- PRIVACY: Does the system collect, process, or generate sensitive data about individuals or groups?\n",
    "- EXPLAINABILITY: Are the system's decisions transparent and interpretable to users and stakeholders?\n",
    "- ECOLOGICAL IMPACT: Could the system directly or indirectly cause environmental harm?\n",
    "\n",
    "First, identify the TWO MOST SIGNIFICANT risks specific to this particular project.\n",
    "Then, assign an overall risk level (low, medium, or high) based on your analysis.\n",
    "Finally, provide 3 HIGHLY SPECIFIC mitigation suggestions that directly address the identified risks for THIS PROJECT.\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "Return your response in this exact format:\n",
    "\n",
    "IDEA_ID: {idea_id}\n",
    "RISK_LEVEL: [low/medium/high]\n",
    "MITIGATION_SUGGESTIONS:\n",
    "1. [First project-specific mitigation suggestion that addresses a concrete risk]\n",
    "2. [Second project-specific mitigation suggestion with technical or procedural detail]\n",
    "3. [Third project-specific mitigation suggestion with measurable outcomes]\n",
    "\n",
    "Your mitigation suggestions must be SPECIFIC to this project, ACTIONABLE, and DIVERSE. Do not use generic solutions that could apply to any AI system. Each suggestion should be substantially different from the otherGs.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T18:39:19.985188Z",
     "start_time": "2025-05-09T18:39:19.983133Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_ideas(path: str) -> list:\n",
    "    \"\"\"Load project ideas from JSON produced by Agent 2.\"\"\"\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T18:39:20.038806Z",
     "start_time": "2025-05-09T18:39:20.031878Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_ethics_check(text: str) -> dict:\n",
    "    \"\"\"Extract ethics and risk check information from the LLM response.\"\"\"\n",
    "    # Clean up the text\n",
    "    text = text.replace('```', '').strip()\n",
    "\n",
    "    # Initialize variables\n",
    "    idea_id = None\n",
    "    risk_level = None\n",
    "    mitigation_suggestions = []\n",
    "\n",
    "    # Keep track of section we're processing\n",
    "    in_suggestions = False\n",
    "\n",
    "    # Process line by line\n",
    "    for line in text.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        # Extract idea ID\n",
    "        if line.startswith(\"IDEA_ID:\"):\n",
    "            idea_id = line[len(\"IDEA_ID:\"):].strip()\n",
    "\n",
    "        # Extract risk level\n",
    "        elif line.startswith(\"RISK_LEVEL:\"):\n",
    "            risk_value = line[len(\"RISK_LEVEL:\"):].strip().lower()\n",
    "            # Normalize risk value to one of the expected values\n",
    "            if \"low\" in risk_value:\n",
    "                risk_level = \"low\"\n",
    "            elif \"medium\" in risk_value or \"med\" in risk_value:\n",
    "                risk_level = \"medium\"\n",
    "            elif \"high\" in risk_value:\n",
    "                risk_level = \"high\"\n",
    "            else:\n",
    "                # Default if unable to determine\n",
    "                risk_level = \"medium\"\n",
    "\n",
    "        # Track when we're in the mitigation suggestions section\n",
    "        elif line.startswith(\"MITIGATION_SUGGESTIONS:\"):\n",
    "            in_suggestions = True\n",
    "\n",
    "        # Extract numbered suggestions\n",
    "        elif in_suggestions and (line.startswith(\"1.\") or line.startswith(\"2.\") or\n",
    "                                line.startswith(\"3.\") or re.match(r\"^\\d+\\.\", line)):\n",
    "            # Extract the suggestion text without the number prefix\n",
    "            suggestion = re.sub(r\"^\\d+\\.\\s*\", \"\", line).strip()\n",
    "            if suggestion:\n",
    "                mitigation_suggestions.append(suggestion)\n",
    "\n",
    "        # Handle suggestions that might not be numbered\n",
    "        elif in_suggestions and not any(line.startswith(prefix) for prefix in\n",
    "                                     [\"IDEA_ID:\", \"RISK_LEVEL:\", \"MITIGATION_SUGGESTIONS:\"]):\n",
    "            # This could be a continuation of suggestions or an unmarked suggestion\n",
    "            if not mitigation_suggestions or len(mitigation_suggestions) >= 3:\n",
    "                # Start a new suggestion if we have none or already have 3+\n",
    "                mitigation_suggestions.append(line)\n",
    "            else:\n",
    "                # Might be a continuation of the last suggestion\n",
    "                mitigation_suggestions[-1] += \" \" + line\n",
    "\n",
    "    # If we found fewer than 3 suggestions but found some text after MITIGATION_SUGGESTIONS,\n",
    "    # try to split it into separate suggestions\n",
    "    if in_suggestions and len(mitigation_suggestions) < 3:\n",
    "        # Look for sentences that could be separate suggestions\n",
    "        extra_text = \" \".join(mitigation_suggestions)\n",
    "        sentences = re.findall(r'[^.!?]+[.!?]', extra_text)\n",
    "        if len(sentences) >= 3:\n",
    "            mitigation_suggestions = [s.strip() for s in sentences[:3]]\n",
    "\n",
    "    # Ensure we have exactly 3 suggestions\n",
    "    while len(mitigation_suggestions) < 3:\n",
    "        mitigation_suggestions.append(\"Ensure regular ethical review of the project.\")\n",
    "\n",
    "    # Truncate to 3 if we found more\n",
    "    mitigation_suggestions = mitigation_suggestions[:3]\n",
    "\n",
    "    # Use default values if parsing failed\n",
    "    if not idea_id:\n",
    "        idea_id = \"unknown_id\"\n",
    "\n",
    "    if not risk_level:\n",
    "        risk_level = \"medium\"\n",
    "\n",
    "    # Return as a dictionary in the expected format\n",
    "    return {\n",
    "        \"idea_id\": idea_id,\n",
    "        \"risk_level\": risk_level,\n",
    "        \"mitigation_suggestions\": mitigation_suggestions\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T18:39:20.087006Z",
     "start_time": "2025-05-09T18:39:20.082042Z"
    }
   },
   "outputs": [],
   "source": [
    "def assess_risk(idea: dict) -> dict:\n",
    "    \"\"\"Assess overall risk and mitigation suggestions for a single idea.\"\"\"\n",
    "    # Format the prompt with all necessary fields\n",
    "    prompt = PROMPT_TEMPLATE.format(\n",
    "        title=idea['title'],\n",
    "        description=idea['description'],\n",
    "        idea_id=idea.get('idea_id', '')\n",
    "    )\n",
    "\n",
    "    print(f\"Assessing risks for idea: {idea.get('idea_id', '')}\")\n",
    "\n",
    "    try:\n",
    "        # Try chat API first\n",
    "        response = ollama.chat(\n",
    "            model=AGENT_7,  # Make sure AGENT_7 is defined\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        text = response['message']['content'] if 'message' in response else str(response)\n",
    "    except Exception as e:\n",
    "        print(f\"Chat API error: {e}, falling back to generate\")\n",
    "        try:\n",
    "            # Fallback to generate API\n",
    "            response = ollama.generate(model=AGENT_7, prompt=prompt)\n",
    "            if hasattr(response, 'message'):\n",
    "                text = response.message.content\n",
    "            elif isinstance(response, dict) and 'response' in response:\n",
    "                text = response['response']\n",
    "            else:\n",
    "                text = str(response)\n",
    "        except Exception as e2:\n",
    "            print(f\"Generate API error: {e2}\")\n",
    "            text = f\"Error calling LLM: {e2}\"\n",
    "\n",
    "    # Save raw response for debugging\n",
    "    debug_file = f\"output/debug/risk_debug_{idea.get('idea_id', 'unknown')}.txt\"\n",
    "    with open(debug_file, \"w\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "    print(f\"Raw response saved to {debug_file}\")\n",
    "\n",
    "    try:\n",
    "        # Use our new parsing function\n",
    "        result = extract_ethics_check(text)\n",
    "\n",
    "        # Log what we found\n",
    "        print(f\"Parsed risk level: {result['risk_level']}\")\n",
    "        print(f\"Found {len(result['mitigation_suggestions'])} mitigation suggestions\")\n",
    "\n",
    "        # Ensure idea_id is correct\n",
    "        if result['idea_id'] != idea.get('idea_id', ''):\n",
    "            print(f\"Warning: Extracted idea_id '{result['idea_id']}' doesn't match expected '{idea.get('idea_id', '')}'\")\n",
    "            result['idea_id'] = idea.get('idea_id', '')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing response: {e}\")\n",
    "        # Provide default values if parsing fails\n",
    "        result = {\n",
    "            \"idea_id\": idea.get('idea_id', ''),\n",
    "            \"risk_level\": \"medium\",\n",
    "            \"mitigation_suggestions\": [\n",
    "                \"Ensure transparent documentation of model limitations and potential biases.\",\n",
    "                \"Implement robust data governance and privacy protection measures.\",\n",
    "                \"Establish regular ethical review processes throughout development and deployment.\"\n",
    "            ]\n",
    "        }\n",
    "        print(\"Using default risk assessment due to parsing error\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T18:54:10.952235Z",
     "start_time": "2025-05-09T18:39:20.131415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting Agent 7: Ethics & Risk Checker ===\n",
      "Loaded 20 ideas from output/agent2_ideas.json\n",
      "\n",
      "Processing idea 1/20: Arctic Anomaly Detection with Computer Vision\n",
      "Assessing risks for idea: 8_arctic_anomaly_detection_with_computer_vision\n",
      "Raw response saved to output/debug/risk_debug_8_arctic_anomaly_detection_with_computer_vision.txt\n",
      "Parsed risk level: medium\n",
      "Found 3 mitigation suggestions\n",
      "Risk level: \u001b[93mmedium\u001b[0m\n",
      "Mitigation suggestions:\n",
      "  1. **Implement region-specific bias audits** by validating model performance across all Arctic sub-regions (e.g., Greenland, Siberia, Canadian Arctic) using stratified sampling during training and testing to ensure equitable detection accuracy.\n",
      "  2. **Integrate model-agnostic explanation tools** (e.g., SHAP or LIME) to generate interpretable heatmaps of CNN outputs, highlighting specific spectral bands and spatial features contributing to anomaly classifications for stakeholders.\n",
      "  3. **Develop a feedback loop with Arctic Indigenous communities** to ground-truth model predictions and annotate edge cases, reducing regional blind spots while ensuring culturally informed validation.\n",
      "\n",
      "Processing idea 2/20: Climate Resilience Prediction using GANs\n",
      "Assessing risks for idea: 9_climate_resilience_prediction_using_gans\n",
      "Raw response saved to output/debug/risk_debug_9_climate_resilience_prediction_using_gans.txt\n",
      "Parsed risk level: high\n",
      "Found 3 mitigation suggestions\n",
      "Risk level: \u001b[91mhigh\u001b[0m\n",
      "Mitigation suggestions:\n",
      "  1. Implement a data diversity audit to ensure training datasets include underrepresented regions and ecosystems, using metrics like geographic coverage and socio-ecological variability.\n",
      "  2. Integrate a post-hoc explanation framework (e.g., SHAP values or LIME) to provide stakeholders with visualizations of how GAN-generated scenarios prioritize certain resilience factors over others.\n",
      "  3. Establish a carbon offset program for model training, tracking energy consumption and compensating for emissions through verified environmental projects.\n",
      "\n",
      "Processing idea 3/20: Sea Level Rise Prediction with Deep Learning\n",
      "Assessing risks for idea: 10_sea_level_rise_prediction_with_deep_learning\n",
      "Raw response saved to output/debug/risk_debug_10_sea_level_rise_prediction_with_deep_learning.txt\n",
      "Parsed risk level: medium\n",
      "Found 3 mitigation suggestions\n",
      "Risk level: \u001b[93mmedium\u001b[0m\n",
      "Mitigation suggestions:\n",
      "  1. **Implement geographically stratified data sampling and regional validation benchmarks** to address potential BIAS. Ensure training data includes underrepresented coastal regions (e.g., small island nations) by weighting historical data to reflect geographic diversity, and mandate post-deployment audits comparing model accuracy across regions with varying socio-ecological vulnerability.\n",
      "  2. **Embed model-agnostic explainability layers (e.g., SHAP values) specific to spatiotemporal transformer outputs** to enhance EXPLAINABILITY. Develop interactive visualizations that highlight which oceanic/temperature variables most influence regional predictions, enabling policymakers to trace high-risk forecasts to observable physical processes.\n",
      "  3. **Integrate real-time feedback mechanisms with coastal community stakeholders** to iteratively refine model outputs. Establish a participatory validation pipeline where local experts and affected populations review model predictions and provide qualitative insights, ensuring outputs align with on-the-ground observations and reducing over-reliance on opaque AI forecasts.\n",
      "\n",
      "Processing idea 4/20: Renewable Energy Output Forecasting\n",
      "Assessing risks for idea: 11_renewable_energy_output_forecasting\n",
      "Raw response saved to output/debug/risk_debug_11_renewable_energy_output_forecasting.txt\n",
      "Parsed risk level: high\n",
      "Found 3 mitigation suggestions\n",
      "Risk level: \u001b[91mhigh\u001b[0m\n",
      "Mitigation suggestions:\n",
      "  1. **Implement geospatial bias audits** by training the model on satellite and weather data from diverse geographic regions (e.g., arid vs. tropical climates) and validating performance across underrepresented areas using fairness metrics like regional prediction error variance. Partner with energy providers in these regions to collect ground-truth sensor data for calibration.\n",
      "  2. **Integrate model-agnostic explainability tools** (e.g., SHAP values or LIME) specifically for the computer vision component analyzing cloud cover. Develop a visualization dashboard that highlights regions of satellite imagery most influential to predictions, enabling grid operators to validate cloud cover interpretations against real-world conditions.\n",
      "  3. **Establish a feedback-driven retraining pipeline** that incorporates real-time sensor data and operator feedback from grid management systems. Use this data to iteratively refine the model, ensuring adaptability to evolving weather patterns and reducing long-term bias from static training datasets. Measure success via annual reductions in regional prediction error disparities (e.g., <10% variance across all regions).\n",
      "\n",
      "Processing idea 5/20: Climate Policy Optimization with Reinforcement Learning\n",
      "Assessing risks for idea: 12_climate_policy_optimization_with_reinforcement_lea\n",
      "Raw response saved to output/debug/risk_debug_12_climate_policy_optimization_with_reinforcement_lea.txt\n",
      "Parsed risk level: high\n",
      "Found 3 mitigation suggestions\n",
      "Risk level: \u001b[91mhigh\u001b[0m\n",
      "Mitigation suggestions:\n",
      "  1. **Incorporate fairness-aware reward functions** that explicitly penalize policy recommendations disproportionately harming marginalized communities (e.g., weighting social equity metrics like Gini coefficient or regional disparity indices in the reward structure).\n",
      "  2. **Implement model-agnostic explanation tools** (e.g., SHAP, LIME) tailored to the RL agent's policy outputs, ensuring stakeholders can trace how specific economic, environmental, or social variables influenced a recommendation (e.g., visualizing trade-offs between carbon taxes and employment rates).\n",
      "  3. **Conduct stakeholder-informed bias audits** with diverse regional representatives to validate policy recommendations against real-world equity benchmarks (e.g., requiring 90% alignment with UN Sustainable Development Goals criteria for social inclusion).\n",
      "\n",
      "Processing idea 6/20: Sustainable Deep Learning Models for Energy Efficiency\n",
      "Assessing risks for idea: 13_sustainable_deep_learning_models_for_energy_effici\n",
      "Raw response saved to output/debug/risk_debug_13_sustainable_deep_learning_models_for_energy_effici.txt\n",
      "Parsed risk level: medium\n",
      "Found 3 mitigation suggestions\n",
      "Risk level: \u001b[93mmedium\u001b[0m\n",
      "Mitigation suggestions:\n",
      "  1. Implement a **geographically diverse dataset curation protocol** that includes underrepresented regions and marginalized communities, with mandatory bias audits during training to ensure performance parity across climate zones.\n",
      "  2. Integrate **model-agnostic explainability tools (e.g., SHAP, LIME)** directly into the pruning pipeline to maintain post-pruning interpretability metrics, ensuring lightweight models retain at least 85% of pre-pruning explainability scores.\n",
      "  3. Develop a **lifecycle carbon-tracking framework** to monitor deployment impacts, including regional performance disparities and energy savings, with quarterly audits to adjust for unintended ecological trade-offs or biased resource allocation.\n",
      "\n",
      "Processing idea 7/20: Climate Data Fusion for Enhanced Predictions\n",
      "Assessing risks for idea: 14_climate_data_fusion_for_enhanced_predictions\n",
      "Raw response saved to output/debug/risk_debug_14_climate_data_fusion_for_enhanced_predictions.txt\n",
      "Parsed risk level: medium\n",
      "Found 3 mitigation suggestions\n",
      "Risk level: \u001b[93mmedium\u001b[0m\n",
      "Mitigation suggestions:\n",
      "  1. Implement **geospatial weighting normalization** during training to account for uneven data coverage across regions, ensuring underrepresented areas (e.g., low-income countries with sparse ground sensors) are not downweighted by attention mechanisms.\n",
      "  2. Develop **attention-anchored explanation maps** that visualize which data modalities (satellite, sensors, oceanographic) drive specific predictions, validated by climate scientists to align with physical plausibility and domain knowledge.\n",
      "  3. Establish a **bias-audit protocol** using synthetic regional stress tests (e.g., simulating sensor failure in data-scarce regions) to quantify prediction accuracy degradation and iteratively adjust model architecture or data fusion strategies to close gaps.\n",
      "\n",
      "Processing idea 8/20: AI-Driven Carbon Footprint Analysis\n",
      "Assessing risks for idea: 15_ai-driven_carbon_footprint_analysis\n",
      "Raw response saved to output/debug/risk_debug_15_ai-driven_carbon_footprint_analysis.txt\n",
      "Parsed risk level: high\n",
      "Found 3 mitigation suggestions\n",
      "Risk level: \u001b[91mhigh\u001b[0m\n",
      "Mitigation suggestions:\n",
      "  1. **Implement bias-aware data curation pipelines** to ensure training data includes geographically and economically diverse regions, industries, and supply chain structures. Prioritize inclusion of underrepresented sectors (e.g., small-scale agriculture, informal economies) to prevent skewed predictions that could marginalize vulnerable groups.\n",
      "  2. **Develop a GNN-specific explainability module** that visualizes critical nodes/edges in the graph (e.g., high-emission supply chain links) using techniques like gradient-based node importance scoring or attention-weighted path tracing, ensuring stakeholders can audit model reasoning without requiring domain expertise.\n",
      "  3. **Conduct annual bias audits** measuring prediction accuracy disparities across income levels and regions, with a target of reducing regional prediction error gaps by ≥30% within 2 years, validated through third-party climate equity impact assessments.\n",
      "\n",
      "Processing idea 9/20: Geoengineering Impact Assessment with Simulations\n",
      "Assessing risks for idea: 16_geoengineering_impact_assessment_with_simulations\n",
      "Raw response saved to output/debug/risk_debug_16_geoengineering_impact_assessment_with_simulations.txt\n",
      "Parsed risk level: high\n",
      "Found 3 mitigation suggestions\n",
      "Risk level: \u001b[91mhigh\u001b[0m\n",
      "Mitigation suggestions:\n",
      "  1. **Incorporate regional climate justice metrics into model training**: Explicitly embed socio-environmental vulnerability data (e.g., crop yields, water scarcity indices) for marginalized regions into the physics-informed neural networks to ensure simulations account for disproportionate regional impacts of geoengineering proposals.\n",
      "  2. **Implement a dual-use impact review board for model outputs**: Establish an interdisciplinary board (climate scientists, ethicists, and civil society representatives) to audit and validate all simulation results before public release, ensuring misuse risks (e.g., justifying harmful geoengineering deployments) are proactively flagged.\n",
      "  3. **Develop real-time feedback visualization tools for stakeholders**: Create interactive dashboards that translate model predictions into geospatially explicit, layperson-accessible visualizations (e.g., rainfall shifts per region, temperature anomalies), enabling non-technical users to verify assumptions and challenge potential biases in the simulations.\n",
      "\n",
      "Processing idea 10/20: Climate Tipping Points Prediction with Predictive Analytics\n",
      "Assessing risks for idea: 17_climate_tipping_points_prediction_with_predictive_\n",
      "Raw response saved to output/debug/risk_debug_17_climate_tipping_points_prediction_with_predictive_.txt\n",
      "Parsed risk level: medium\n",
      "Found 3 mitigation suggestions\n",
      "Risk level: \u001b[93mmedium\u001b[0m\n",
      "Mitigation suggestions:\n",
      "  1. **Integrate geographically diverse and underrepresented datasets** (e.g., satellite, ground-sensor, and indigenous ecological knowledge) into model training to reduce regional prediction bias, ensuring Amazon and Arctic regions are weighted proportionally to their ecological significance.\n",
      "  2. **Implement model-agnostic explainability frameworks** (e.g., SHAP values, partial dependence plots) to trace how variables like deforestation rates or methane emissions influence tipping point predictions, paired with stakeholder workshops to validate interpretations.\n",
      "  3. **Establish a feedback loop with local experts and communities** in high-risk regions to audit model outputs, quantify prediction accuracy gaps (e.g., reduce false negatives in permafrost thaw forecasts by 20% annually), and iteratively refine data inputs based on on-the-ground observations.\n",
      "\n",
      "Processing idea 11/20: Machine Learning for Climate Adaptation Strategies\n",
      "Assessing risks for idea: 18_machine_learning_for_climate_adaptation_strategies\n",
      "Raw response saved to output/debug/risk_debug_18_machine_learning_for_climate_adaptation_strategies.txt\n",
      "Parsed risk level: high\n",
      "Found 3 mitigation suggestions\n",
      "Risk level: \u001b[91mhigh\u001b[0m\n",
      "Mitigation suggestions:\n",
      "  1. **Implement fairness-aware training pipelines** using reweighing or adversarial debiasing to counteract historical inequities in socio-economic data. Partner with local communities to validate adaptation strategies and ensure equitable resource allocation across marginalized groups.\n",
      "  2. **Deploy federated learning frameworks** to train the AI on decentralized regional datasets (e.g., local government databases) without centralizing sensitive socio-economic or vulnerability data, reducing exposure risks and ensuring compliance with privacy regulations like GDPR.\n",
      "  3. **Integrate SHAP-based explainability modules** to generate region-specific, plain-language rationales for adaptation strategies (e.g., \"Flood barriers prioritized here due to 70% higher projected rainfall in low-income neighborhoods\"). Track stakeholder adoption rates and equity metrics (e.g., % of underrepresented groups included in strategy planning) to measure fairness outcomes.\n",
      "\n",
      "Processing idea 12/20: Environmental Predictive Modeling with Transformers\n",
      "Assessing risks for idea: 19_environmental_predictive_modeling_with_transformer\n",
      "Raw response saved to output/debug/risk_debug_19_environmental_predictive_modeling_with_transformer.txt\n",
      "Parsed risk level: medium\n",
      "Found 3 mitigation suggestions\n",
      "Risk level: \u001b[93mmedium\u001b[0m\n",
      "Mitigation suggestions:\n",
      "  1. Conduct rigorous geographic and ecological bias audits of training data by stratifying satellite imagery and species distribution datasets across underrepresented regions (e.g., low-income tropical zones) and applying bias correction algorithms like adversarial debiasing to ensure equitable prediction accuracy.\n",
      "  2. Implement a dual-layer data access control system: (1) encrypt sensitive region-specific datasets using homomorphic encryption during model training, and (2) restrict real-time API access to verified stakeholders via cryptographic authentication tokens with audit trails to prevent misuse by bad actors.\n",
      "  3. Integrate a model-interpretability pipeline using attention-heatmapping overlays on satellite imagery to visually explain prediction factors (e.g., highlighting deforestation hotspots) and quantify stakeholder trust metrics through biannual feedback surveys, aiming for ≥85% user confidence in decision-making.\n",
      "\n",
      "Processing idea 13/20: Climate Justice Analysis using AI\n",
      "Assessing risks for idea: 20_climate_justice_analysis_using_ai\n",
      "Raw response saved to output/debug/risk_debug_20_climate_justice_analysis_using_ai.txt\n",
      "Parsed risk level: high\n",
      "Found 3 mitigation suggestions\n",
      "Risk level: \u001b[91mhigh\u001b[0m\n",
      "Mitigation suggestions:\n",
      "  1. **Implement fairness-aware NLP algorithms** to detect and correct biases in policy language analysis, ensuring that the model does not disproportionately misinterpret or overlook marginalized communities' concerns. For example, incorporate domain-specific fairness metrics (e.g., equity in representation of low-income or Indigenous groups) during training.\n",
      "  2. **Adopt federated learning frameworks** to process sensitive social vulnerability data (e.g., health, income, housing) without centralizing it, reducing privacy risks. Integrate k-anonymity or differential privacy techniques when aggregating results to prevent re-identification of individuals or communities.\n",
      "  3. **Develop a community co-validation protocol** where affected stakeholders (e.g., representatives from marginalized groups) review AI-generated policy equity scores, providing feedback to refine model outputs. This ensures transparency and aligns the system’s interpretations with on-the-ground realities.\n",
      "\n",
      "Processing idea 14/20: Machine Learning-Based Weather Forecasting for Agriculture\n",
      "Assessing risks for idea: 21_machine_learning-based_weather_forecasting_for_agr\n",
      "Raw response saved to output/debug/risk_debug_21_machine_learning-based_weather_forecasting_for_agr.txt\n",
      "Parsed risk level: medium\n",
      "Found 3 mitigation suggestions\n",
      "Risk level: \u001b[93mmedium\u001b[0m\n",
      "Mitigation suggestions:\n",
      "  1. **Implement geospatially balanced data collection protocols** to ensure training datasets include underrepresented regions (e.g., smallholder farms in arid zones) by deploying subsidized sensor networks in marginalized agricultural areas, paired with bias-detection algorithms to flag regional prediction disparities.\n",
      "  2. **Integrate model-agnostic explainability tools (e.g., SHAP values)** directly into the user interface, highlighting how soil moisture sensor trends and weather station inputs influence hyper-local forecasts, enabling farmers to validate predictions against observable field conditions.\n",
      "  3. **Conduct annual third-party audits** to assess algorithmic fairness across socioeconomic groups, measuring metrics like prediction accuracy variance between high-income and subsistence farms, with public reporting and mandatory model updates to reduce disparities >15%.\n",
      "\n",
      "Processing idea 15/20: Climate Model Uncertainty Quantification with Bayesian Neural Networks\n",
      "Assessing risks for idea: 22_climate_model_uncertainty_quantification_with_baye\n",
      "Raw response saved to output/debug/risk_debug_22_climate_model_uncertainty_quantification_with_baye.txt\n",
      "Parsed risk level: medium\n",
      "Found 3 mitigation suggestions\n",
      "Risk level: \u001b[93mmedium\u001b[0m\n",
      "Mitigation suggestions:\n",
      "  1. **Implement model-agnostic uncertainty visualization tools** to map Bayesian neural network outputs onto geospatial climate variables, ensuring policymakers can trace how regional biases in input data (e.g., underrepresented tropical regions) affect projected uncertainties.\n",
      "  2. **Conduct adversarial sensitivity testing** by injecting synthetic regional climate data with known biases into the training pipeline, then measuring how Bayesian posterior distributions shift to quantify and correct for latent geographic or demographic data imbalances.\n",
      "  3. **Deploy energy-efficient probabilistic inference frameworks** (e.g., variational dropout or stochastic gradient Langevin dynamics) to reduce computational carbon footprint by 40% while maintaining uncertainty quantification accuracy, with real-time CO₂ emission tracking integrated into model training logs.\n",
      "\n",
      "Processing idea 16/20: Climate Decision Support Systems with Multi-Agent Reinforcement Learning\n",
      "Assessing risks for idea: 23_climate_decision_support_systems_with_multi-agent_\n",
      "Raw response saved to output/debug/risk_debug_23_climate_decision_support_systems_with_multi-agent_.txt\n",
      "Parsed risk level: high\n",
      "Found 3 mitigation suggestions\n",
      "Risk level: \u001b[91mhigh\u001b[0m\n",
      "Mitigation suggestions:\n",
      "  1. **Implement a bias detection module with equity-weighted reward functions**: Integrate a module that audits MARL outputs for regional and socio-economic disparities by comparing simulated outcomes against historical climate policy data. Adjust the reward functions to explicitly prioritize equity metrics (e.g., carbon burden distribution across low-income vs. high-income regions) during training.\n",
      "  2. **Incorporate attention-based interpretability layers**: Design the MARL architecture to include attention mechanisms that explicitly highlight which stakeholder interactions (e.g., government-industry negotiations) most influenced a recommendation. This provides stakeholders with a traceable \"decision tree\" of simulated interactions, improving transparency without sacrificing model complexity.\n",
      "  3. **Establish a real-world stakeholder validation loop**: Conduct quarterly workshops with diverse stakeholders (e.g., policymakers from Global South countries, environmental NGOs) to test system outputs in controlled scenarios. Require the system to demonstrate measurable alignment with UN SDGs (e.g., reducing projected emissions disparities by ≥15% in simulated low-income regions) before deployment.\n",
      "\n",
      "Processing idea 17/20: Sustainable Development Optimization with AI\n",
      "Assessing risks for idea: 24_sustainable_development_optimization_with_ai\n",
      "Raw response saved to output/debug/risk_debug_24_sustainable_development_optimization_with_ai.txt\n",
      "Parsed risk level: high\n",
      "Found 3 mitigation suggestions\n",
      "Risk level: \u001b[91mhigh\u001b[0m\n",
      "Mitigation suggestions:\n",
      "  1. **Conduct bias-awareness audits using geospatial and socioeconomic datasets** that explicitly include marginalized communities, ensuring optimization algorithms prioritize historically underserved regions. Integrate fairness constraints (e.g., demographic parity or equal opportunity metrics) into the objective function to prevent resource allocation disparities.\n",
      "  2. **Implement model-agnostic explainability frameworks (e.g., SHAP values or LIME)** to visualize how each optimization decision balances economic, environmental, and social factors. Embed these explanations into interactive dashboards for stakeholders to trace trade-offs between circular economy metrics (e.g., material reuse rates vs. job creation in low-income areas).\n",
      "  3. **Establish a multidisciplinary oversight panel** with representatives from affected communities, sustainability experts, and algorithmic transparency specialists to review optimization outputs quarterly. Require the system to generate **annual equity impact reports** measuring reductions in regional resource inequality (e.g., Gini coefficient for access to renewable energy or clean water post-optimization).\n",
      "\n",
      "Processing idea 18/20: AI for Climate Governance and Policy Implementation\n",
      "Assessing risks for idea: 25_ai_for_climate_governance_and_policy_implementatio\n",
      "Raw response saved to output/debug/risk_debug_25_ai_for_climate_governance_and_policy_implementatio.txt\n",
      "Parsed risk level: high\n",
      "Found 3 mitigation suggestions\n",
      "Risk level: \u001b[91mhigh\u001b[0m\n",
      "Mitigation suggestions:\n",
      "  1. **Conduct bias audits of training datasets and enforcement strategies** by analyzing historical compliance data for regional, economic, or political disparities. For example, ensure the system does not disproportionately flag low-income nations for non-compliance due to incomplete or unrepresentative data.\n",
      "  2. **Implement a hybrid explainability framework** that combines rule-based system transparency with NLP model interpretability tools (e.g., SHAP values or LIME) to generate human-readable justifications for enforcement recommendations. This would require integrating a visualization dashboard showing how policy violations are detected and prioritized.\n",
      "  3. **Establish an independent, multilateral oversight panel** composed of legal experts, climate scientists, and AI ethicists to validate the system’s recommendations. Require the panel to review at least 10% of high-stakes enforcement actions annually, with a measurable outcome of reducing biased or unexplainable decisions by ≥30% within 12 months.\n",
      "\n",
      "Processing idea 19/20: Climate Informatics for Carbon Footprint Visualization\n",
      "Assessing risks for idea: 26_climate_informatics_for_carbon_footprint_visualiza\n",
      "Raw response saved to output/debug/risk_debug_26_climate_informatics_for_carbon_footprint_visualiza.txt\n",
      "Parsed risk level: high\n",
      "Found 3 mitigation suggestions\n",
      "Risk level: \u001b[91mhigh\u001b[0m\n",
      "Mitigation suggestions:\n",
      "  1. Implement a bias detection framework that audits the training data for geographic and sectoral representation, applying fairness-aware algorithms to adjust for underrepresented regions in supply chain and transportation data.\n",
      "  2. Integrate model-agnostic explainability tools like SHAP (SHapley Additive exPlanations) into the dashboard to provide real-time visual explanations of how specific data points (e.g., energy consumption patterns) influence carbon footprint calculations.\n",
      "  3. Develop a feedback loop where stakeholders from diverse regions can validate the accuracy of their carbon footprint visualizations and report discrepancies, enabling iterative model refinement based on real-world data from underrepresented areas.\n",
      "\n",
      "Processing idea 20/20: Climate Scenario Planning with Generative Models\n",
      "Assessing risks for idea: 27_climate_scenario_planning_with_generative_models\n",
      "Raw response saved to output/debug/risk_debug_27_climate_scenario_planning_with_generative_models.txt\n",
      "Parsed risk level: high\n",
      "Found 3 mitigation suggestions\n",
      "Risk level: \u001b[91mhigh\u001b[0m\n",
      "Mitigation suggestions:\n",
      "  1. **Incorporate geographically diverse and underrepresented climate datasets** into the generative model training pipeline, prioritizing data from vulnerable regions (e.g., small island nations, arid zones) to reduce bias in simulated scenarios. Use data augmentation techniques like synthetic oversampling for underrepresented regions to ensure equitable risk assessment.\n",
      "  2. **Develop a scenario explanation framework** that visualizes model inputs, latent variables, and uncertainty ranges (e.g., via SHAP values or attention maps for diffusion models) to clarify how climate factors (e.g., RCPs, regional vulnerabilities) influence generated outcomes, ensuring stakeholders can audit model logic.\n",
      "  3. **Implement energy-efficient training protocols** using model distillation or pruning to reduce computational costs, and offset carbon emissions by partnering with verified climate initiatives (e.g., Renewable Energy Certificates), with measurable outcomes tracked via a public emissions dashboard.\n",
      "\n",
      "Writing 20 risk assessments to output/agent7_risks.json\n",
      "\n",
      "=== Risk Assessment Summary ===\n",
      "Total ideas processed: 20\n",
      "Risk levels: 0 low, 8 medium, 12 high\n",
      "Results saved to output/agent7_risks.json\n",
      "=== Agent 7 completed successfully ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_agent7():\n",
    "    \"\"\"Run ethics & risk checker on all ideas and save results.\"\"\"\n",
    "    print(\"\\n=== Starting Agent 7: Ethics & Risk Checker ===\")\n",
    "\n",
    "    try:\n",
    "        # Load ideas\n",
    "        ideas = load_ideas(INPUT_FILE)\n",
    "        print(f\"Loaded {len(ideas)} ideas from {INPUT_FILE}\")\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        # Process each idea with progress tracking\n",
    "        for i, idea in enumerate(ideas):\n",
    "            print(f\"\\nProcessing idea {i+1}/{len(ideas)}: {idea.get('title', 'Untitled')}\")\n",
    "            try:\n",
    "                assessment = assess_risk(idea)\n",
    "                outputs.append(assessment)\n",
    "\n",
    "                # Print a summary of the assessment\n",
    "                risk_level = assessment.get('risk_level', 'unknown')\n",
    "                risk_color = {\n",
    "                    'low': '\\033[92m',    # Green\n",
    "                    'medium': '\\033[93m',  # Yellow\n",
    "                    'high': '\\033[91m'     # Red\n",
    "                }.get(risk_level.lower(), '')\n",
    "                reset_color = '\\033[0m'\n",
    "\n",
    "                print(f\"Risk level: {risk_color}{risk_level}{reset_color}\")\n",
    "                print(\"Mitigation suggestions:\")\n",
    "                for j, suggestion in enumerate(assessment.get('mitigation_suggestions', []), 1):\n",
    "                    print(f\"  {j}. {suggestion}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"ERROR processing idea {idea.get('idea_id', '')}: {e}\")\n",
    "                # Create a default assessment to avoid breaking the pipeline\n",
    "                outputs.append({\n",
    "                    \"idea_id\": idea.get('idea_id', f\"unknown_{i}\"),\n",
    "                    \"risk_level\": \"medium\",\n",
    "                    \"mitigation_suggestions\": [\n",
    "                        \"Implement robust data governance policies.\",\n",
    "                        \"Ensure transparent documentation of model limitations.\",\n",
    "                        \"Establish regular ethical review processes.\"\n",
    "                    ]\n",
    "                })\n",
    "\n",
    "        # Write results to file\n",
    "        print(f\"\\nWriting {len(outputs)} risk assessments to {OUTPUT_FILE}\")\n",
    "        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
    "            json.dump(outputs, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        # Generate summary statistics\n",
    "        risk_counts = {\n",
    "            'low': 0,\n",
    "            'medium': 0,\n",
    "            'high': 0\n",
    "        }\n",
    "\n",
    "        for output in outputs:\n",
    "            risk = output.get('risk_level', '').lower()\n",
    "            if risk in risk_counts:\n",
    "                risk_counts[risk] += 1\n",
    "\n",
    "        print(\"\\n=== Risk Assessment Summary ===\")\n",
    "        print(f\"Total ideas processed: {len(outputs)}\")\n",
    "        print(f\"Risk levels: {risk_counts['low']} low, {risk_counts['medium']} medium, {risk_counts['high']} high\")\n",
    "        print(f\"Results saved to {OUTPUT_FILE}\")\n",
    "        print(\"=== Agent 7 completed successfully ===\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"CRITICAL ERROR in Agent 7: {e}\")\n",
    "        print(\"Agent 7 failed to complete\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_agent7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T18:54:11.005483Z",
     "start_time": "2025-05-09T18:54:11.003927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied output/agent2_ideas.json → output/3IdeaPasses/agent2_ideas.json\n",
      "Copied output/agent2_raw_llm_output.txt → output/3IdeaPasses/agent2_raw_llm_output.txt\n",
      "Copied output/agent4.json → output/3IdeaPasses/agent4.json\n",
      "Copied output/task4.json → output/3IdeaPasses/task4.json\n",
      "Copied output/agent5_co2.json → output/3IdeaPasses/agent5_co2.json\n",
      "Copied output/agent6_impact.json → output/3IdeaPasses/agent6_impact.json\n",
      "Copied output/agent7_risks.json → output/3IdeaPasses/agent7_risks.json\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# 1) Source and destination directories\n",
    "source_dir = Path('./output')\n",
    "dest_dir   = Path('./output/3IdeaPasses')\n",
    "\n",
    "# 2) Ensure the destination exists\n",
    "dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 3) List of filenames to move\n",
    "files = [\n",
    "    'agent2_ideas.json',\n",
    "    'agent2_raw_llm_output.txt',\n",
    "    'task4.json',\n",
    "    'agent5_co2.json',\n",
    "    'agent6_impact.json',\n",
    "    'agent7_risks.json'\n",
    "]\n",
    "\n",
    "# 4) Move each one\n",
    "for fname in files:\n",
    "    src = source_dir / fname\n",
    "    dst = dest_dir   / fname\n",
    "    if src.exists():\n",
    "        shutil.copy(str(src), str(dst))\n",
    "        print(f\"Copied {src} → {dst}\")\n",
    "    else:\n",
    "        print(f\"{src} not found, skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-ollama-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
